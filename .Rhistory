label.x = 0.5, label.y = 0.10,
parse = TRUE, coef.digits = 5) +
theme_classic()
ggplot(data = dados, mapping = aes(x = Avg_Utilization_Ratio, y = Total_Revolving_Bal)) +
geom_point() +
geom_smooth(method = "lm", col = "red") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 0.05,
parse = TRUE, coef.digits = 5) +
theme_classic()
dados$Avg_revolving_per <- (dados$Total_Revolving_Bal/dados$Total_Trans_Amt)
plot(dados$Total_Revolving_Bal/dados$Total_Trans_Amt)
plot(dados$Total_Revolving_Bal,dados$Total_Trans_Amt)
plot(dados$Total_Trans_Amt,dados$Total_Revolving_Bal,)
plot(dados$Avg_Utilization_Ratio, dados$Total_Revolving_Bal,)
plot(dados$Avg_Utilization_Ratio, dados$Avg_revolving_per)
mod <- lm(Avg_Utilization_Ratio ~ Avg_revolving_per, dados)
summary(mod)
ggplot(data = dados, mapping = aes(x = Avg_Utilization_Ratio, y = Total_Revolving_Bal)) +
geom_point() +
geom_smooth(method = "lm", col = "green") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.05, label.y = 400,
parse = TRUE, coef.digits = 5) +
theme_classic()
ggplot(data = dados, mapping = aes(x = Avg_Utilization_Ratio, y = Total_Revolving_Bal)) +
geom_point() +
geom_smooth(method = "lm", col = "green") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.05, label.y = 400,
parse = TRUE, coef.digits = 5) +
theme_classic()
ggplot(data = dados, mapping = aes(x = Avg_Utilization_Ratio, y = Total_Revolving_Bal)) +
geom_point() +
geom_smooth(method = "lm", col = "green") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 10,
parse = TRUE, coef.digits = 5) +
theme_classic()
ggplot(data = dados, mapping = aes(x = Avg_Utilization_Ratio, y = Total_Revolving_Bal)) +
geom_point() +
geom_smooth(method = "lm", col = "green") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 0.05,
parse = TRUE, coef.digits = 5) +
theme_classic()
# Defina a semente para reproduzibilidade
set.seed(56)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Total_Revolving_Bal, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
# validar a igualdade das amostras
boxplot(conjunto_treinamento$Total_Revolving_Bal,conjunto_teste$Total_Revolving_Bal)
# Criar um modelo de Regressão Linear
modelo_lin <- lm(Total_Revolving_Bal ~ Avg_Utilization_Ratio, dados)
summary(modelo_lin)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(error = FALSE)
options(repos = "https://cran.rstudio.com")
rm(list = ls())
if(!require(pacman)) install.packages("pacman")
library(pacman)
pacman::p_load(tidyverse,
Hmisc,
stargazer,
visdat,
rmarkdown,
knitr,
GGally,
summarytools,
extremevalues,
DataExplorer,
gplots,
ggplot2,
SmartEDA,
kableExtra,
e1071,
caret,
rstatix,
lmtest,
ggpmisc
)
p_loaded()
dados <- read.csv("publicidade.csv")
dados <- read.csv2("publicidade.csv")
#varificar se há alguma linha repetida
anyDuplicated(dados)
#Exploração da estrutura do data frame - visão 1
ExpData(dados,type=1)
ExpData(dados,type=1)
#Exploração da estrutura do data frame - visão 2
ExpData(dados,type=2)
ExpData(dados,type=2)
str(dados)
plot_intro(dados)
plot(dados$Publicidade,dados$Vendas)
vcor <- round(cor(dados$Publicidade,dados$Vendas),3)
print(paste("A correlacao entre as variaveis e de:",vcor))
dados <- read.csv2("publicidade.csv")
# excluir as ultimas duas colunas para ocultar o resultado anterior do projeto
dados <- dados[ ,1:21]
dados <- read.csv2("publicidade.csv")
#varificar se há alguma linha repetida
anyDuplicated(dados)
#Exploração da estrutura do data frame - visão 1
ExpData(dados,type=1)
#Exploração da estrutura do data frame - visão 2
ExpData(dados,type=2)
#Exploração da estrutura do data frame - visão 3
str(dados)
#Exploração da estrutura do data frame - visão 4
plot_intro(dados)
# Avaliação da relação linear entre as variáveis:
plot(dados$Publicidade,dados$Vendas)
vcor <- round(cor(dados$Publicidade,dados$Vendas),3)
print(paste("A correlacao entre as variaveis e de:",vcor))
# Defina a semente para reproduzibilidade
set.seed(1234)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Vendas, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
# validar a igualdade das amostras
boxplot(conjunto_treinamento$Vendas,conjunto_teste$Vendas)
# Criar um modelo de Regressão Linear
modelo_lin <- lm(Vendas ~ Publicidade, dados)
# Defina a semente para reproduzibilidade
set.seed(58)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Vendas, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
# validar a igualdade das amostras
boxplot(conjunto_treinamento$Vendas,conjunto_teste$Vendas)
# Criar um modelo de Regressão Linear
modelo_lin <- lm(Vendas ~ Publicidade, dados)
# Análise gráfica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpretação: https://data.library.virginia.edu/diagnostic-plots/
## Normalidade dos resíduos:
shapiro.test(modelo_lin$residuals)
## Outliers nos resíduos:
summary(rstandard(modelo_lin))
## Independência dos resíduos (Durbin-Watson):
durbinWatsonTest(modelo_lin)
bptest(modelo_lin)
## Resultados do Modelo
summary(modelo_lin)
ggplot(data = dados, mapping = aes(x = Avg_Utilization_Ratio, y = Total_Revolving_Bal)) +
geom_point() +
geom_smooth(method = "lm", col = "green") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 0.05,
parse = TRUE, coef.digits = 5) +
theme_classic()
ggplot(data = dados, mapping = aes(x = Publicidade, y = Vendas)) +
geom_point() +
geom_smooth(method = "lm", col = "blue") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 0.05,
parse = TRUE, coef.digits = 5) +
theme_classic()
dados$Vendas_pr <- 125.17951+(conjunto_teste$Publicidade*0.10495)
# Fazer previsões
dados$Vendas_pr <- (125.17951+(conjunto_teste$Publicidade*0.10495))
# Fazer previsões
conjunto_teste$Vendas_pr <- 125.17951+(conjunto_teste$Publicidade*0.10495)
View(conjunto_teste)
### Avaliação numérica
conjunto_teste$dif <- conjunto_teste$Vendas-conjunto_teste$Vendas_pr
summary(conjunto_teste$dif)
### Avaliação pela diferença % da previsão
conjunto_teste$dif_p <- (conjunto_teste$Vendas_pr/conjunto_teste$Vendas)
summary(conjunto_teste$dif)
summary(conjunto_teste$dif_p)
### Avaliação pela diferença % da previsão
conjunto_teste$dif_p <- (conjunto_teste$dif/conjunto_teste$Vendas)
summary(conjunto_teste$dif_p)
### Avaliação visual
ggplot(data = dados, mapping = aes(x = Publicidade, y = Vendas)) +
geom_point() +
geom_smooth(method = "lm", col = "blue") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 0.05,
parse = TRUE, coef.digits = 5) +
theme_classic()
### Avaliação pela diferença da previsão
conjunto_teste$dif <- conjunto_teste$Vendas-conjunto_teste$Vendas_pr
summary(conjunto_teste$dif)
### Avaliação pela diferença % da previsão
conjunto_teste$dif_p <- (conjunto_teste$dif/conjunto_teste$Vendas)
summary(conjunto_teste$dif_p)
# Fazer previsões
conjunto_teste$Vendas_pr <- 125.17951+(conjunto_teste$Publicidade*0.10495)
# Análise gráfica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpretação: https://data.library.virginia.edu/diagnostic-plots/
## Normalidade dos resíduos:
shapiro.test(modelo_lin$residuals)
## Outliers nos resíduos:
summary(rstandard(modelo_lin))
## Homocedasticidade (Breusch-Pagan):
bptest(modelo_lin)
## Independência dos resíduos (Durbin-Watson):
durbinWatsonTest(modelo_lin)
par(mfrow=c(2,2))
plot(modelo_lin)
### Avaliação visual
ggplot(data = dados, mapping = aes(x = Publicidade, y = Vendas)) +
geom_point() +
geom_smooth(method = "lm", col = "blue") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 0.05,
parse = TRUE, coef.digits = 5) +
theme_classic()
### Avaliação pela diferença da previsão
conjunto_teste$dif <- conjunto_teste$Vendas-conjunto_teste$Vendas_pr
summary(conjunto_teste$dif)
### Avaliação pela diferença % da previsão
conjunto_teste$dif_p <- (conjunto_teste$dif/conjunto_teste$Vendas)
summary(conjunto_teste$dif_p)
cor.test(dados$Publicidade,dados$Vendas,
alternative = "two.sided",
method = "pearson",
exact = NULL, conf.level = 0.95, continuity = FALSE, ...)
cor.test(dados$Publicidade,dados$Vendas)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(error = FALSE)
options(repos = "https://cran.rstudio.com")
rm(list = ls())
if(!require(pacman)) install.packages("pacman")
library(pacman)
pacman::p_load(tidyverse,
Hmisc,
stargazer,
visdat,
rmarkdown,
knitr,
GGally,
summarytools,
extremevalues,
DataExplorer,
gplots,
ggplot2,
SmartEDA,
kableExtra,
e1071,
caret,
rstatix,
lmtest,
ggpmisc
)
p_loaded()
dados <- read.csv2("publicidade.csv")
#varificar se há alguma linha repetida
anyDuplicated(dados)
#Exploração da estrutura do data frame - visão 1
ExpData(dados,type=1)
#Exploração da estrutura do data frame - visão 2
ExpData(dados,type=2)
#Exploração da estrutura do data frame - visão 3
str(dados)
#Exploração da estrutura do data frame - visão 4
plot_intro(dados)
# Avaliação da relação linear entre as variáveis:
plot(dados$Publicidade,dados$Vendas)
vcor <- round(cor(dados$Publicidade,dados$Vendas),3)
print(paste("A correlacao entre as variaveis e de:",vcor))
cor.test(dados$Publicidade,dados$Vendas,
alternative = "two.sided",
method = "pearson",
exact = NULL, conf.level = 0.95, continuity = FALSE, ...)
cor.test(dados$Publicidade,dados$Vendas,
alternative = "two.sided",
method = "pearson",
exact = NULL, conf.level = 0.95, continuity = FALSE, ...)
cor.test(dados$Publicidade,dados$Vendas)
cor.test(dados$Publicidade,dados$Vendas,
alternative = "two.sided",
method = "pearson",
exact = NULL, conf.level = 0.95, continuity = FALSE)
vcor <- cor.test(dados$Publicidade,dados$Vendas,
alternative = "two.sided",
method = "pearson",
exact = NULL, conf.level = 0.95, continuity = FALSE)
vcor
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(error = FALSE)
options(repos = "https://cran.rstudio.com")
rm(list = ls())
if(!require(pacman)) install.packages("pacman")
library(pacman)
pacman::p_load(tidyverse,
Hmisc,
stargazer,
visdat,
rmarkdown,
knitr,
GGally,
summarytools,
extremevalues,
DataExplorer,
gplots,
ggplot2,
SmartEDA,
kableExtra,
e1071,
caret,
rstatix,
lmtest,
ggpmisc
)
p_loaded()
dados <- read.csv2("publicidade.csv")
#varificar se há alguma linha repetida
anyDuplicated(dados)
#Exploração da estrutura do data frame - visão 1
ExpData(dados,type=1)
#Exploração da estrutura do data frame - visão 2
ExpData(dados,type=2)
#Exploração da estrutura do data frame - visão 3
str(dados)
#Exploração da estrutura do data frame - visão 4
plot_intro(dados)
# Avaliação da relação linear entre as variáveis:
plot(dados$Publicidade,dados$Vendas)
cor.test(dados$Publicidade,dados$Vendas,
alternative = "two.sided",
method = "pearson",
exact = NULL, conf.level = 0.95, continuity = FALSE)
# Defina a semente para reproduzibilidade
set.seed(58)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Vendas, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
# validar a igualdade das amostras
boxplot(conjunto_treinamento$Vendas,conjunto_teste$Vendas)
# Criar um modelo de Regressão Linear
modelo_lin <- lm(Vendas ~ Publicidade, dados)
# Análise gráfica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpretação: https://data.library.virginia.edu/diagnostic-plots/
## Normalidade dos resíduos:
shapiro.test(modelo_lin$residuals)
## Outliers nos resíduos:
summary(rstandard(modelo_lin))
## Homocedasticidade (Breusch-Pagan):
bptest(modelo_lin)
## Independência dos resíduos (Durbin-Watson):
#durbinWatsonTest(modelo_lin)
## Resultados do Modelo
summary(modelo_lin)
# Fazer previsões
conjunto_teste$Vendas_pr <- 125.17951+(conjunto_teste$Publicidade*0.10495)
### Avaliação visual
ggplot(data = dados, mapping = aes(x = Publicidade, y = Vendas)) +
geom_point() +
geom_smooth(method = "lm", col = "blue") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 0.05,
parse = TRUE, coef.digits = 5) +
theme_classic()
### Avaliação pela diferença da previsão
conjunto_teste$dif <- conjunto_teste$Vendas-conjunto_teste$Vendas_pr
summary(conjunto_teste$dif)
### Avaliação pela diferença % da previsão
conjunto_teste$dif_p <- (conjunto_teste$dif/conjunto_teste$Vendas)
summary(conjunto_teste$dif_p)
View(conjunto_teste)
plot(conu)
summary(conjunto_teste$dif)
summary(conjunto_teste$dif)
summary(conjunto_teste$dif, conf.level = 0.95)
t.test(conjunto_teste$dif)
ExpNumStat(conjunto_teste$dif)
ExpNumStat(conjunto_teste)
### Avaliação pela diferença % da previsão
conjunto_teste$dif_p <- abs((conjunto_teste$dif/conjunto_teste$Vendas))
summary(conjunto_teste$dif_p)
### Avaliação visual
ggplot(data = dados, mapping = aes(x = Publicidade, y = Vendas)) +
geom_point() +
geom_smooth(method = "lm", col = "blue") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 0.05,
parse = TRUE, coef.digits = 5) +
theme_classic()
### Avaliação pela diferença da previsão
conjunto_teste$dif <- conjunto_teste$Vendas-conjunto_teste$Vendas_pr
summary(conjunto_teste$dif)
### Avaliação pela diferença % da previsão
conjunto_teste$dif_p <- abs((conjunto_teste$dif/conjunto_teste$Vendas))
summary(conjunto_teste$dif_p)
View(conjunto_treinamento)
View(conjunto_teste)
mean(conjunto_teste$Vendas)
mean(conjunto_teste$Vendas_pr)
=181/185
181/185
4/18
4/185
mean(conjunto_teste$dif_p)
### Avaliação visual
ggplot(data = dados, mapping = aes(x = Publicidade, y = Vendas)) +
geom_point() +
geom_smooth(method = "lm", col = "blue") +
stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
sep = "*plain(\",\")~~")),
label.x = 0.5, label.y = 0.05,
parse = TRUE, coef.digits = 5) +
theme_classic()
### Avaliação pela diferença da previsão - critério exclusivamente gerencial!!!
conjunto_teste$dif <- conjunto_teste$Vendas-conjunto_teste$Vendas_pr
summary(conjunto_teste$dif)
t.test(conjunto_teste$dif)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(error = FALSE)
options(repos = "https://cran.rstudio.com")
rm(list = ls())
if(!require(pacman)) install.packages("pacman")
library(pacman)
pacman::p_load(tidyverse,
Hmisc,
stargazer,
visdat,
rmarkdown,
knitr,
GGally,
summarytools,
extremevalues,
DataExplorer,
gplots,
ggplot2,
SmartEDA,
kableExtra,
e1071,
caret,
rstatix,
lmtest,
ggpmisc,
car
)
p_loaded()
dados <- read.csv2("publicidade.csv")
#varificar se há alguma linha repetida
anyDuplicated(dados)
#Exploração da estrutura do data frame - visão 1
ExpData(dados,type=1)
#Exploração da estrutura do data frame - visão 2
ExpData(dados,type=2)
#Exploração da estrutura do data frame - visão 3
str(dados)
#Exploração da estrutura do data frame - visão 4
plot_intro(dados)
# Avaliação da relação linear entre as variáveis:
plot(dados$Publicidade,dados$Vendas)
cor.test(dados$Publicidade,dados$Vendas,
alternative = "two.sided",
method = "pearson",
exact = NULL, conf.level = 0.95, continuity = FALSE)
# Defina a semente para reproduzibilidade
set.seed(58)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Vendas, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
# validar a igualdade das amostras
boxplot(conjunto_treinamento$Vendas,conjunto_teste$Vendas)
# Criar um modelo de Regressão Linear
modelo_lin <- lm(Vendas ~ Publicidade, dados)
# Análise gráfica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpretação: https://data.library.virginia.edu/diagnostic-plots/
## Normalidade dos resíduos:
shapiro.test(modelo_lin$residuals)
## Outliers nos resíduos:
summary(rstandard(modelo_lin))
## Homocedasticidade (Breusch-Pagan):
bptest(modelo_lin)
## Independência dos resíduos (Durbin-Watson):
durbinWatsonTest(modelo_lin)
## Resultados do Modelo
summary(modelo_lin)
pairs.panels(dados)
library(psych)
pairs.panels(dados)
