---
title: "SIMPLE LINEAR REGRESSION MODEL"
author: "MarTech IPAM 2024"
date: "2024-03-01"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, }
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(error = FALSE)


```

# Simple Linear Regression Model - Predict Sales

## 1. Setup do ambiente

### 1.1 Instala√ß√£o e leitura das bibliotecas (pacotes) necess√°rios
```{r}


rm(list = ls())
if(!require(pacman)) install.packages("pacman")
library(pacman)

pacman::p_load(tidyverse,
                 Hmisc,
                 stargazer,
                 visdat,
                 rmarkdown, 
                 knitr, 
                 GGally, 
                 summarytools,
                 extremevalues,
                 DataExplorer,
                 gplots,
                 ggplot2,
                 SmartEDA,
                 kableExtra,
                 e1071,
                 caret,
                 rstatix,
                 lmtest,
                 ggpmisc,
                 car,
                 psych
                 )
p_loaded()

```

### 1.2 Carga e vista geral do ficheiro

```{r}


dados <- read.csv2("publicidade.csv")

#varificar se h√° alguma linha repetida
anyDuplicated(dados)

#Explora√ß√£o da estrutura do data frame - vis√£o 1
ExpData(dados,type=1) 
#Explora√ß√£o da estrutura do data frame - vis√£o 2
ExpData(dados,type=2) 
#Explora√ß√£o da estrutura do data frame - vis√£o 3
str(dados) 
#Explora√ß√£o da estrutura do data frame - vis√£o 4
plot_intro(dados)

# Avalia√ß√£o da rela√ß√£o linear entre as vari√°veis:
plot(dados$Publicidade,dados$Vendas)
cor.test(dados$Publicidade,dados$Vendas,
         alternative = "two.sided",
         method = "pearson",
         exact = NULL, conf.level = 0.95, continuity = FALSE)




```

## 2 Machine Learning

### 2.1 Treinamento do modelo
```{r}
# Defina a semente para reproduzibilidade
set.seed(58)

# define a propor√ß√£o de dados que ser√° usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Vendas, p = 0.7, list = FALSE)

# Crie conjuntos de treinamento e teste com base nos √≠ndices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]

# validar a igualdade das amostras
boxplot(conjunto_treinamento$Vendas,conjunto_teste$Vendas)


# Criar um modelo de Regress√£o Linear
modelo_lin <- lm(Vendas ~ Publicidade, dados)


```

### 2.2 Valida√ß√£o dos Pressupostos
```{r}
# An√°lise gr√°fica:
par(mfrow=c(2,2))
plot(modelo_lin)
### Interpreta√ß√£o: https://data.library.virginia.edu/diagnostic-plots/

# (ES) gr√°fico Residuals vs Fitted (ajustamento dos res√≠duos), comprava a linearidade dos res√≠duos, 
# para isso deve ter a linha vermelha na horizontal.

# (DS) Normal Q-Q (gr√°fico QQ Plot) demonstra a normalidade dos res√≠duos, deve ser apoiado pelo teste de Shapiro Wilk

# (EI) Scale Location (valida a homocedasticidade dos res√≠duos)
# o gr√°fico deve apresentar uma distribui√ß√£o dos pontos de forma aleat√≥ria

# (DI) Residuals vs Leverage - outliers e pontos influentes dos res√≠duos
# algo fora do padr√£o ir√° estar acima de linha pontilhada

## Normalidade dos res√≠duos:
## H0 = H√° normalidade nos dados
shapiro.test(modelo_lin$residuals)

## Outliers nos res√≠duos:
## tendo os res√≠duos estandarizados, devemos observar se algum deles passa do valor 3
summary(rstandard(modelo_lin))

## Homocedasticidade (Breusch-Pagan):H0 h√° homocedasticidade
bptest(modelo_lin)

## Independ√™ncia dos res√≠duos (Durbin-Watson): H0 autocorrela√ß√£o positiva
## contudo normalmente utilizado para estudos longitudinais com a seguinte leitura
## A estat√≠stica de teste Durbin-Watson toma valores entre 0 e 4. Ao n√≠vel de signific√¢ncia ÔÅ° de 5%: ## ùëë‚âà0, rejeita-se H0 e existe autocorrela√ß√£o positiva
## ùëë‚âà4, rejeita-se H0 e existe autocorrela√ß√£o negativa
##valores pr√≥ximos de 2, tipicamente entre 1.5 e 2.5, n√£o se rejeita H0, assumindo-se a independ√™ncia
durbinWatsonTest(modelo_lin)

## Resultados do Modelo
summary(modelo_lin)

```


### 2.3 uso do modelo para predi√ß√£o do revolving
```{r}
# Fazer previs√µes
conjunto_teste$Vendas_pr <- 125.17951+(conjunto_teste$Publicidade*0.10495)



```

### 2.4 Avaliar a predi√ß√£o
```{r}
### Avalia√ß√£o visual
ggplot(data = dados, mapping = aes(x = Publicidade, y = Vendas)) +
  geom_point() +
  geom_smooth(method = "lm", col = "blue") +
  stat_poly_eq(aes(label = paste(after_stat(eq.label), after_stat(adj.rr.label),
                                 sep = "*plain(\",\")~~")),
               label.x = 0.5, label.y = 0.05,
               parse = TRUE, coef.digits = 5) +
  theme_classic()

### Avalia√ß√£o pela diferen√ßa da previs√£o - crit√©rio exclusivamente gerencial!!!
conjunto_teste$dif <- conjunto_teste$Vendas-conjunto_teste$Vendas_pr
summary(conjunto_teste$dif)
t.test(conjunto_teste$dif)



```

